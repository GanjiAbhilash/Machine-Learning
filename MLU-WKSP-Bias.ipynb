{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"0\">AWEsome Workshop - Identifying and Mitigating Bias in ML</a>\n",
    "\n",
    "__ML Problem:__ \n",
    "The example ML problem for this workshop is a so called binary classification (predicting whether something or someone belongs to a class or not). In this case, we aim to predict whether someone is going to receive a government grant or not. This is a hypothetical prediction problem with an underlying true story:\n",
    "\n",
    "Whether or not someone will receive a grant depends on personal circumstances and all individuals are different. It can be argued that when a human decision maker is approving or denying grants, they can be influenced. This is especially bad if there is a limited resource (e.g. grants) the government can hand out; grants should not be disproportionately awarded to a certain group. Therefore, a machine learning solution is desirable as this can be considered objective decision making. As we will see, this is not necessarily the case. Machine Learning models depend on the input data they use to learn from and said inputs can be inherently biased. \n",
    "\n",
    "The dataset used in this example us using US census information on individuals and was generated using [folktables](https://github.com/zykls/folktables). Folktables provide code to download data from the American Community Survey (ACS) Public Use Microdata Sample (PUMS) files managed by the US Census Bureau. The data itself is governed by the terms of use provided by the Census Bureau.\n",
    "\n",
    "__Notebook Structure:__ \n",
    "In this workshop we will build a classifier to predict if an individual is awarded a government grant or not. The structure of the notebook is outlined below:\n",
    "\n",
    "1. <a href=\"#1\">Read the dataset</a>\n",
    "2. <a href=\"#2\">Data Processing</a>\n",
    "    * <a href=\"#21\">Exploratory Data Analysis</a>\n",
    "    * <a href=\"#22\">Measuring Bias</a>\n",
    "    * <a href=\"#23\">Train - Validation - Test Datasets</a>\n",
    "3. <a href=\"#3\">Training a Classifier</a>\n",
    "    * <a href=\"#31\">Reweighing</a>\n",
    "    * <a href=\"#32\">Model Training</a>\n",
    "    * <a href=\"#33\">Making Predictions w/o Bias Mitigation</a>\n",
    "4. <a href=\"#4\">Measuring Prediction Bias</a>\n",
    "\n",
    "Before we can started with the notebook, we need to load certain libraries. If you have never worked with a Jupyter Notebook before, [this video](https://youtu.be/R1qVqAZfPes?t=85) can be a helpful introduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping/basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Operational libraries\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a name=\"1\">Read the dataset</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Let's import data using [Pandas ` .read_csv()`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"census_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a name=\"2\">Data Processing and Exploration</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Before building a Machine Learning (ML) model, it is very important to analyse the data and check for bias. There are many different ways in which bias can hide in a dataset; for this workshop, we will only look at bias that can arise through sampling issues or historical discrepancies between racial groups in the United States."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 <a name=\"21\">Exploratory Data Analysis</a>\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "We look at number of rows, columns, and some simple statistics of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is: (1000, 11)\n"
     ]
    }
   ],
   "source": [
    "# Check how many rows and columns we have in the data frame\n",
    "print(\"The shape of the dataset is:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data set itself and print the first five rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>RELP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC</th>\n",
       "      <th>PWGTP</th>\n",
       "      <th>SCH</th>\n",
       "      <th>awarded_grant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>237.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEP  COW  SCHL  MAR  RELP  WKHP  SEX RAC  PWGTP  SCH  awarded_grant\n",
       "0  30.0  1.0  21.0  5.0   0.0  50.0  2.0   A  169.0  1.0              1\n",
       "1  19.0  1.0  16.0  5.0   2.0  40.0  1.0   B  102.0  1.0              0\n",
       "2  29.0  1.0  20.0  5.0   2.0  40.0  2.0   A  170.0  1.0              0\n",
       "3  33.0  6.0  16.0  5.0   2.0  20.0  1.0   A  237.0  1.0              0\n",
       "4  46.0  7.0  16.0  3.0   0.0  30.0  1.0   A   81.0  1.0              1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We distinguish between categorical and numerical features\n",
    "categorical_features = [\"COW\", \"SCHL\", \"MAR\", \"RELP\", \"SEX\", \"SCH\"]\n",
    "numerical_features = [\"AGEP\", \"WKHP\", \"PWGTP\"]\n",
    "sensitive_features = [\"RAC\"] # this is an example; depending on context age, gender, ... can be sensitive\n",
    "\n",
    "# We cast categorical features to `category`\n",
    "df[categorical_features] = df[categorical_features].astype(\"object\")\n",
    "\n",
    "# We cast numerical features to `int`\n",
    "df[numerical_features] = df[numerical_features].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we might notice here are the unintuitive feature names; with a few exceptions it is very difficult to understand what the features refer to; e.g. MAR could refer to March. In this context, the data owners are actually encoding the marital status. It could be worthwhile to rename the features, so it will be easier later to understand what they actually refer to. This can be done by creating a renaming dictionary and by using the [Pandas `.rename()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html) method.\n",
    "\n",
    "```\n",
    "# Create dictionary for new column names\n",
    "rename_dict = {\"MAR\":\"marital_status\"} \n",
    "\n",
    "# Apply new names to dataframe\n",
    "df.rename(rename_dict, axis=1, inplace=True)\n",
    "\n",
    "```\n",
    "\n",
    "For now, we will proceed without the renaming, and simply list the mapping between feature name and proceed to separate the model target from the features that we want to use to predict the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We distinguish between features and target (what we want to predict)\n",
    "model_target = \"awarded_grant\"\n",
    "model_features = categorical_features + numerical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start measuring bias, we can look at the data frame again and color the columns based on their type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/n39rnln17tzd7f12lnw6br7w0000gr/T/ipykernel_14008/1188350711.py:3: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "  df.head().style.set_precision(0).set_properties(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0b213_row0_col0, #T_0b213_row0_col5, #T_0b213_row0_col8, #T_0b213_row1_col0, #T_0b213_row1_col5, #T_0b213_row1_col8, #T_0b213_row2_col0, #T_0b213_row2_col5, #T_0b213_row2_col8, #T_0b213_row3_col0, #T_0b213_row3_col5, #T_0b213_row3_col8, #T_0b213_row4_col0, #T_0b213_row4_col5, #T_0b213_row4_col8 {\n",
       "  background-color: #c2ebbb;\n",
       "}\n",
       "#T_0b213_row0_col1, #T_0b213_row0_col2, #T_0b213_row0_col3, #T_0b213_row0_col4, #T_0b213_row0_col6, #T_0b213_row0_col9, #T_0b213_row1_col1, #T_0b213_row1_col2, #T_0b213_row1_col3, #T_0b213_row1_col4, #T_0b213_row1_col6, #T_0b213_row1_col9, #T_0b213_row2_col1, #T_0b213_row2_col2, #T_0b213_row2_col3, #T_0b213_row2_col4, #T_0b213_row2_col6, #T_0b213_row2_col9, #T_0b213_row3_col1, #T_0b213_row3_col2, #T_0b213_row3_col3, #T_0b213_row3_col4, #T_0b213_row3_col6, #T_0b213_row3_col9, #T_0b213_row4_col1, #T_0b213_row4_col2, #T_0b213_row4_col3, #T_0b213_row4_col4, #T_0b213_row4_col6, #T_0b213_row4_col9 {\n",
       "  background-color: #eaddde;\n",
       "}\n",
       "#T_0b213_row0_col7, #T_0b213_row1_col7, #T_0b213_row2_col7, #T_0b213_row3_col7, #T_0b213_row4_col7 {\n",
       "  background-color: #dae0e9;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0b213_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >AGEP</th>\n",
       "      <th class=\"col_heading level0 col1\" >COW</th>\n",
       "      <th class=\"col_heading level0 col2\" >SCHL</th>\n",
       "      <th class=\"col_heading level0 col3\" >MAR</th>\n",
       "      <th class=\"col_heading level0 col4\" >RELP</th>\n",
       "      <th class=\"col_heading level0 col5\" >WKHP</th>\n",
       "      <th class=\"col_heading level0 col6\" >SEX</th>\n",
       "      <th class=\"col_heading level0 col7\" >RAC</th>\n",
       "      <th class=\"col_heading level0 col8\" >PWGTP</th>\n",
       "      <th class=\"col_heading level0 col9\" >SCH</th>\n",
       "      <th class=\"col_heading level0 col10\" >awarded_grant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0b213_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0b213_row0_col0\" class=\"data row0 col0\" >30</td>\n",
       "      <td id=\"T_0b213_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_0b213_row0_col2\" class=\"data row0 col2\" >21</td>\n",
       "      <td id=\"T_0b213_row0_col3\" class=\"data row0 col3\" >5</td>\n",
       "      <td id=\"T_0b213_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_0b213_row0_col5\" class=\"data row0 col5\" >50</td>\n",
       "      <td id=\"T_0b213_row0_col6\" class=\"data row0 col6\" >2</td>\n",
       "      <td id=\"T_0b213_row0_col7\" class=\"data row0 col7\" >A</td>\n",
       "      <td id=\"T_0b213_row0_col8\" class=\"data row0 col8\" >169</td>\n",
       "      <td id=\"T_0b213_row0_col9\" class=\"data row0 col9\" >1</td>\n",
       "      <td id=\"T_0b213_row0_col10\" class=\"data row0 col10\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0b213_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0b213_row1_col0\" class=\"data row1 col0\" >19</td>\n",
       "      <td id=\"T_0b213_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "      <td id=\"T_0b213_row1_col2\" class=\"data row1 col2\" >16</td>\n",
       "      <td id=\"T_0b213_row1_col3\" class=\"data row1 col3\" >5</td>\n",
       "      <td id=\"T_0b213_row1_col4\" class=\"data row1 col4\" >2</td>\n",
       "      <td id=\"T_0b213_row1_col5\" class=\"data row1 col5\" >40</td>\n",
       "      <td id=\"T_0b213_row1_col6\" class=\"data row1 col6\" >1</td>\n",
       "      <td id=\"T_0b213_row1_col7\" class=\"data row1 col7\" >B</td>\n",
       "      <td id=\"T_0b213_row1_col8\" class=\"data row1 col8\" >102</td>\n",
       "      <td id=\"T_0b213_row1_col9\" class=\"data row1 col9\" >1</td>\n",
       "      <td id=\"T_0b213_row1_col10\" class=\"data row1 col10\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0b213_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_0b213_row2_col0\" class=\"data row2 col0\" >29</td>\n",
       "      <td id=\"T_0b213_row2_col1\" class=\"data row2 col1\" >1</td>\n",
       "      <td id=\"T_0b213_row2_col2\" class=\"data row2 col2\" >20</td>\n",
       "      <td id=\"T_0b213_row2_col3\" class=\"data row2 col3\" >5</td>\n",
       "      <td id=\"T_0b213_row2_col4\" class=\"data row2 col4\" >2</td>\n",
       "      <td id=\"T_0b213_row2_col5\" class=\"data row2 col5\" >40</td>\n",
       "      <td id=\"T_0b213_row2_col6\" class=\"data row2 col6\" >2</td>\n",
       "      <td id=\"T_0b213_row2_col7\" class=\"data row2 col7\" >A</td>\n",
       "      <td id=\"T_0b213_row2_col8\" class=\"data row2 col8\" >170</td>\n",
       "      <td id=\"T_0b213_row2_col9\" class=\"data row2 col9\" >1</td>\n",
       "      <td id=\"T_0b213_row2_col10\" class=\"data row2 col10\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0b213_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_0b213_row3_col0\" class=\"data row3 col0\" >33</td>\n",
       "      <td id=\"T_0b213_row3_col1\" class=\"data row3 col1\" >6</td>\n",
       "      <td id=\"T_0b213_row3_col2\" class=\"data row3 col2\" >16</td>\n",
       "      <td id=\"T_0b213_row3_col3\" class=\"data row3 col3\" >5</td>\n",
       "      <td id=\"T_0b213_row3_col4\" class=\"data row3 col4\" >2</td>\n",
       "      <td id=\"T_0b213_row3_col5\" class=\"data row3 col5\" >20</td>\n",
       "      <td id=\"T_0b213_row3_col6\" class=\"data row3 col6\" >1</td>\n",
       "      <td id=\"T_0b213_row3_col7\" class=\"data row3 col7\" >A</td>\n",
       "      <td id=\"T_0b213_row3_col8\" class=\"data row3 col8\" >237</td>\n",
       "      <td id=\"T_0b213_row3_col9\" class=\"data row3 col9\" >1</td>\n",
       "      <td id=\"T_0b213_row3_col10\" class=\"data row3 col10\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0b213_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_0b213_row4_col0\" class=\"data row4 col0\" >46</td>\n",
       "      <td id=\"T_0b213_row4_col1\" class=\"data row4 col1\" >7</td>\n",
       "      <td id=\"T_0b213_row4_col2\" class=\"data row4 col2\" >16</td>\n",
       "      <td id=\"T_0b213_row4_col3\" class=\"data row4 col3\" >3</td>\n",
       "      <td id=\"T_0b213_row4_col4\" class=\"data row4 col4\" >0</td>\n",
       "      <td id=\"T_0b213_row4_col5\" class=\"data row4 col5\" >30</td>\n",
       "      <td id=\"T_0b213_row4_col6\" class=\"data row4 col6\" >1</td>\n",
       "      <td id=\"T_0b213_row4_col7\" class=\"data row4 col7\" >A</td>\n",
       "      <td id=\"T_0b213_row4_col8\" class=\"data row4 col8\" >81</td>\n",
       "      <td id=\"T_0b213_row4_col9\" class=\"data row4 col9\" >1</td>\n",
       "      <td id=\"T_0b213_row4_col10\" class=\"data row4 col10\" >1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f82a5f5c8b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply styling to the data frame columns to visually see which column is which data type\n",
    "\n",
    "df.head().style.set_precision(0).set_properties(\n",
    "    **{\"background-color\": \"#eaddde\"}, subset=categorical_features\n",
    ").set_properties(\n",
    "    **{\"background-color\": \"#c2ebbb\"}, subset=numerical_features\n",
    ").set_properties(\n",
    "    **{\"background-color\": \"#dae0e9\"}, subset=sensitive_features\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 <a name=\"21\">Measuring Bias</a>\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "Let's check our target distribution to see if we have biased labels. First, we can look at the labels without overlay of the group membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(\n",
    "    x=model_target,\n",
    "    data=df,\n",
    "    hue_order=[1, 0],\n",
    "    kind=\"count\",\n",
    "    palette=sns.husl_palette(2),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that we are dealing with an imbalanced dataset. This means there are more examples for one type of results (here: 0; meaning individuals not awarded grants). The question now: Will the target distribution be similar per group or is there one group in the data set that has more individuals awarded grants than not. We start with a plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 435.375x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(\n",
    "    x=\"RAC\",\n",
    "    kind=\"count\",\n",
    "    hue=model_target,\n",
    "    hue_order=[0, 1],\n",
    "    data=df,\n",
    "    palette=sns.husl_palette(2),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the ratio of outcomes vastly differs per group (i.e. Group B has a much worse ratio of individuals awarded grants vs. not). To analyse this in more detail, we need to separate out the groups and calculate the **Difference in Proportion of Labels**. We might also want to know how the *sizes* of the groups compare overall; for this, we calculate **Normalized Class Imbalance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized Class Imbalance (CI)\n",
    "To calculate class imbalance, we compare the number of individuals per group by subtracting. To normalize, we divide by the total number of individuals in the data set. The equation for Normalized Class Imbalance is therefore:\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "<center>$CI = \\frac{n_{RAC=A} - n_{RAC=B}}{n_{RAC=A} + n_{RAC=B}}$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_A = len(df[df[\"RAC\"] == \"A\"])  # n_RAC=\"A\"\n",
    "n_B = len(df[df[\"RAC\"] == \"B\"])  # n_RAC=\"B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.676\n"
     ]
    }
   ],
   "source": [
    "# Implement the equation for CI\n",
    "# Use the variables n_A and n_B to complete the equation\n",
    "\n",
    "ci = (n_A-n_B)/(n_A+n_B)\n",
    "\n",
    "print(ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference in Proportion of Labels (DPL)\n",
    "The difference in proportions of labels (DPL) compares the proportion of the labels with positive outcome for Group A with the proportion of labels with positive outcome of Group B. One important thing to note: It is always important to think about the meaning of the label and relate it to what can be considered \"positive\" in a given context.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<center>$DPL = \\frac{n_{eligible \\wedge RAC=A}}{n_{RAC=A}} - \\frac{n_{eligible \\wedge RAC=B}}{n_{RAC=B}}$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eligible_A = len(df[(df[\"RAC\"] == \"A\") & (df[model_target] == 1)])\n",
    "n_eligible_B = len(df[(df[\"RAC\"] == \"B\") & (df[model_target] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28617519667639\n"
     ]
    }
   ],
   "source": [
    "# Implement the equation for DPL\n",
    "# Use the variables defined above to complete the equation\n",
    "\n",
    "dpl = (n_eligible_A/n_A)-(n_eligible_B/n_B)\n",
    "\n",
    "print(dpl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which group is disproportionately favored? You can have a look at the [definition of DPL](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-data-bias-metric-true-label-imbalance.html) or the slides for help. \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DPL values range over the interval [-1, 1]. If DPL is close enough to 0, then we say that demographic parity has been achieved. The closer to 0 the better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 <a name=\"23\">Train - Test Datasets</a>\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "A standard step when building Machine Learning models is to split the data into several separate data frames (some of which will be used to train/learn a model and others to evaluate it). For more details about the this step, have a look at an interactive article [here](https://mlu.corp.amazon.com/explain/train-test-validation). In this notebook, we will use [Sklearn's `train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) method to split the data.\n",
    "\n",
    "Don't worry about fully understanding this; we are including the code as it is standard practice in Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Test datasets shapes:  (900, 11) (100, 11)\n"
     ]
    }
   ],
   "source": [
    "# We split the dataframe (df) into a train (90%) and test (20%) set\n",
    "train_data, test_data = train_test_split(\n",
    "    df, test_size=0.1, shuffle=True, random_state=1\n",
    ")\n",
    "\n",
    "# Print the shapes of the Train - Test Datasets\n",
    "print(\n",
    "    \"Train - Test datasets shapes: \",\n",
    "    train_data.shape,\n",
    "    test_data.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a name=\"3\">Training a Classifier</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "We are ready to build a model. In this workshop we will implement a KNN classifier. To show the difference bias mitigation has on the result, we will train the KNN classifier in two different ways:\n",
    "1. KNN without bias mitigation \n",
    "2. KNN with bias mitigation (reweighing)\n",
    "\n",
    "To implement the bias mitigation, we first need to calculate the reweighing factors that we can then pass into the KNN algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 <a name=\"31\"> Reweighing</a>\n",
    "(<a href=\"#3\">Go to Train a Classifier</a>)\n",
    "\n",
    "Below you can find the code implementation that will calculate the weights per group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweighing(data, label, sensitive_attr, return_list=True):\n",
    "    label_dict = dict()\n",
    "    try:\n",
    "        # This will loop through the different labels (1 - awarded grant, 0 - not awarded)\n",
    "        for outcome in data[label].unique():\n",
    "            weight_map = dict()\n",
    "            # Check for all possible groups (here we have A & B but there could be more in reality)\n",
    "            for val in data[sensitive_attr].unique():\n",
    "                # Calculate the probabilities\n",
    "                nom = (\n",
    "                    len(data[data[sensitive_attr] == val])\n",
    "                    / len(data)\n",
    "                    * len(data[data[label] == outcome])\n",
    "                    / len(data)\n",
    "                )\n",
    "                denom = len(\n",
    "                    data[(data[sensitive_attr] == val) & (data[label] == outcome)]\n",
    "                ) / len(data)\n",
    "                # Store weights according to sensitive attribute\n",
    "                weight_map[val] = round(nom / denom, 2)\n",
    "            # Store \n",
    "            label_dict[outcome] = weight_map\n",
    "        # Create full list of all weights for every data point provided as input\n",
    "        data[\"weights\"] = list(\n",
    "            map(lambda x, y: label_dict[y][x], data[sensitive_attr], data[label])\n",
    "        )\n",
    "        if return_list == True:\n",
    "            return data[\"weights\"].to_list()\n",
    "        else:\n",
    "            return label_dict\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        print(\"Dataframe might have no entries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the `reweighing` function is a nested dictionary where the outer keys of the dictionary indicate the outcomes (eligible or not). The inner keys in the dictionary correspond to the sensitive groups and the values are the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'A': 0.9, 'B': 2.3}, 0: {'A': 1.09, 'B': 0.71}}\n"
     ]
    }
   ],
   "source": [
    "# 2 outcomes (eligible or not eligible for medicare) and 2 groups (Group A & Group B) yield 4 weighting factors\n",
    "print(reweighing(df, model_target, \"RAC\", return_list=False))\n",
    "\n",
    "# df: this is our data frame\n",
    "# model_target: this is \"awarded_grant\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to calculate the weights for every row of our data frame and store those in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We store all the weights in a list\n",
    "bias_weights = reweighing(df, model_target, \"RAC\", return_list=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 <a name=\"32\">Model Training</a>\n",
    "(<a href=\"#3\">Go to Train a Classifier</a>)\n",
    "\n",
    "We want to use K-Nearest Neighbor classifier for predictions in this workshop. The KNN algorithm follows these steps:\n",
    "1. Calculate distance between the data point that we want to predict for and all data points from the training set\n",
    "2. Sort the distance values from closest to furthest and select k closest (neighbors)\n",
    "3. Check which class the k closest neighbors belong to and assign majority vote as prediction output\n",
    "\n",
    "This algorithm is implemented efficiently in Sklearn. However, the default algorithm does not allow directly for bias mitigation, so we will use a custom KNN implementation. Before we can use KNN, we need to clean up our data frame a little bit and scale all values. Otherwise KNN will simply favor certain predictions based on the scale the feature has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's prepare the training data\n",
    "X_train = train_data[model_features]\n",
    "y_train = train_data[model_target]\n",
    "\n",
    "# Scale the training data to avoid feature scale impacting the results\n",
    "X_train = pd.concat(\n",
    "    [\n",
    "        (X_train[numerical_features] - X_train[numerical_features].min())\n",
    "        / (X_train[numerical_features].max() - X_train[numerical_features].min()),\n",
    "        pd.get_dummies(X_train.drop(numerical_features, axis=1)),\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_Classifier(test_df, n_neighbors=3, weighted=True):\n",
    "    \"\"\"Custom KNN Classifier with bias weight scaling.\"\"\"\n",
    "    # Create empty list to store predictions in\n",
    "    predictions = []\n",
    "    # For every point in the test data, calculate distance to train data\n",
    "    for k in range(len(test_df)):\n",
    "        dis = []\n",
    "        for i in range(len(X_train)):\n",
    "            dis.append(\n",
    "                euclidean_distances(\n",
    "                    test_df.iloc[k].values.reshape(1, -1),\n",
    "                    X_train.iloc[i].values.reshape(1, -1),\n",
    "                )[0][0]\n",
    "            )\n",
    "        # Divide by bias weights to scale data\n",
    "        if weighted == True:\n",
    "            dis_new = [i / j for i, j in zip(dis, bias_weights)]\n",
    "        else:\n",
    "            dis_new = dis\n",
    "        # Find k closest neighbors\n",
    "        neighbors = np.array(dis_new).argsort()[:n_neighbors]\n",
    "        # Select the classes those neighbors have\n",
    "        neighbors_classes = y_train.iloc[neighbors].to_list()\n",
    "        # Create majority vote\n",
    "        majority_vote = max(set(neighbors_classes), key=neighbors_classes.count)\n",
    "        # Store vote as prediction output\n",
    "        predictions.append(majority_vote)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 <a name=\"33\">Making Predictions w/o Bias Mitigation</a>\n",
    "(<a href=\"#3\">Go to Train a Classifier</a>)\n",
    "\n",
    "Before we can make predictions, we need to make sure that data we want to test on is also scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get validation data to validate the classifier\n",
    "X_test = test_data[model_features]\n",
    "y_test = test_data[model_target]\n",
    "\n",
    "# Scale the test data to avoid feature scale impacting the results\n",
    "X_test = pd.concat(\n",
    "    [\n",
    "        (X_test[numerical_features] - X_test[numerical_features].min())\n",
    "        / (X_test[numerical_features].max() - X_test[numerical_features].min()),\n",
    "        pd.get_dummies(X_test.drop(numerical_features, axis=1)),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Finally, we need to make sure that all columns that exist in X_train also exist in X_test\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for the model is to create predictions for both groups that have a DPL value as close to 0 as possible. Therefore, we will train the model with and then without bias mitigation (reweighing) and compare the DPL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = KNN_Classifier(X_test, n_neighbors=5, weighted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, call the `KNN_Classifier` function and set the weight parameter to `True`. Keep the number of neighbors at 5 to make it a fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the code here\n",
    "test_predictions_mitigation = KNN_Classifier(X_test, n_neighbors=5, weighted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a new data frame with all the predictions to make it easier to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RAC</th>\n",
       "      <th>awarded_grant</th>\n",
       "      <th>y_test_pred</th>\n",
       "      <th>y_test_mitigation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RAC  awarded_grant  y_test_pred  y_test_mitigation\n",
       "0   A              0            1                  0\n",
       "1   A              0            1                  0\n",
       "2   A              1            1                  0\n",
       "3   B              0            1                  0\n",
       "4   A              0            0                  0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe that contains predictions and the sensitive attribute\n",
    "pred_df = pd.concat(\n",
    "    [\n",
    "        test_data.reset_index(drop=True)[[\"RAC\", model_target]],\n",
    "        pd.Series(test_predictions, name=\"y_test_pred\"),\n",
    "        pd.Series(test_predictions_mitigation, name=\"y_test_mitigation\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. <a name=\"4\">Measuring Prediction Bias: DPL for Predictions (DPPL)</a> \n",
    "\n",
    "Now that we have predictions we can compare and check several things:\n",
    "- Check what the baseline DPL value is for the test data \n",
    "- Compare how the model with mitigation fares again the baseline\n",
    "- Compare how the model without intervention fares again the baseline\n",
    "\n",
    "#### DPL baseline\n",
    "Let's start by calculating the baseline DPL value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_A_post = len(pred_df[pred_df[\"RAC\"] == \"A\"])  # n_RAC=A\n",
    "n_B_post = len(pred_df[pred_df[\"RAC\"] == \"B\"])  # n_RAC=B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2651072124756335"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_eligible_A_test = len(\n",
    "    pred_df[(pred_df[\"RAC\"] == \"A\") & (pred_df[model_target] == 1)]\n",
    ")\n",
    "n_eligible_B_test = len(\n",
    "    pred_df[(pred_df[\"RAC\"] == \"B\") & (pred_df[model_target] == 1)]\n",
    ")\n",
    "\n",
    "((n_eligible_A_test) / (n_A_post)) - ((n_eligible_B_test) / (n_B_post))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline is pretty much exactly what we saw when calculating DPL across the whole data set (the above is DPL for the test proportion). We can be sure that our test data follows the same distribution as the full data set and proceed to compare the model predictions to the baseline we just established."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DPL for Model with no intervention\n",
    "Let's calculate DPL for the predictions and compare them to the original DPL value (the difference in proportion of labels in the original data frame):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28654970760233917"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_eligible_A_post = len(\n",
    "    pred_df[(pred_df[\"RAC\"] == \"A\") & (pred_df[\"y_test_pred\"] == 1)]\n",
    ")\n",
    "n_eligible_B_post = len(\n",
    "    pred_df[(pred_df[\"RAC\"] == \"B\") & (pred_df[\"y_test_pred\"] == 1)]\n",
    ")\n",
    "\n",
    "# Calculate DPPL for the model with no bias mitmigation\n",
    "((n_eligible_A_post) / (n_A_post)) - ((n_eligible_B_post) / (n_B_post))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the model without bias intervention actually made the situation worse for Group B. Before the model was trained, the DPL value was 0.27; the predictions give a DPL of 0.29. So without any intervention, this model is predicting slightly more biased results vs. the baseline. This is a very small difference and could be due to fluctuation but could also indicate a pattern.\n",
    "\n",
    "\n",
    "#### DPL for Model with bias mitigation\n",
    "Let's have a look at the DPL value for the model that was trained with the bias weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11630929174788823"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_eligible_A_mitigated_post = len(\n",
    "    pred_df[(pred_df[\"RAC\"] == \"A\") & (pred_df[\"y_test_mitigation\"] == 1)]\n",
    ")\n",
    "n_eligible_B_mitigated_post = len(\n",
    "    pred_df[(pred_df[\"RAC\"] == \"B\") & (pred_df[\"y_test_mitigation\"] == 1)]\n",
    ")\n",
    "\n",
    "# Calculate DPPL for the model with bias mitigation\n",
    "((n_eligible_A_mitigated_post) / (n_A_post)) - (\n",
    "    (n_eligible_B_mitigated_post) / (n_B_post)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value looks much better. Clearly the reweighing took effect. While comparing the DPL values is very helpful, it is also advisable to plot the distribution of predictions to visually inspect the behavior.\n",
    "\n",
    "We create three plots below:\n",
    "1. Baseline\n",
    "2. Biased Model\n",
    "3. Mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize figure\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 6))\n",
    "# Set title of figure\n",
    "fig.suptitle(\"Comparison of Model Predictions and Baseline\")\n",
    "\n",
    "# Create first plot of baseline values\n",
    "ax1.bar(\n",
    "    [\"A\", \"B\"],\n",
    "    pred_df[pred_df[model_target] == 0][\"RAC\"].value_counts(),\n",
    "    color=\"#f77189\",\n",
    ")\n",
    "ax1.bar(\n",
    "    [\"A\", \"B\"],\n",
    "    pred_df[pred_df[model_target] == 1][\"RAC\"].value_counts(),\n",
    "    color=\"#36ada4\",\n",
    ")\n",
    "\n",
    "ax1.legend([\"not awarded\", \"awarded\"])\n",
    "ax1.title.set_text('Baseline target distribution')\n",
    "\n",
    "# Create second plot of values without bias mitigation\n",
    "ax2.bar(\n",
    "    [\"A\", \"B\"],\n",
    "    pred_df[pred_df[\"y_test_pred\"] == 0][\"RAC\"].value_counts(),\n",
    "    color=\"#f77189\",\n",
    ")\n",
    "ax2.bar(\n",
    "    [\"A\", \"B\"],\n",
    "    pred_df[pred_df[\"y_test_pred\"] == 1][\"RAC\"].value_counts(),\n",
    "    color=\"#36ada4\",\n",
    ")\n",
    "\n",
    "ax2.legend([\"not awarded\", \"awarded\"])\n",
    "ax2.title.set_text('Predictions without bias mitigation')\n",
    "\n",
    "# Create third plot of values with bias mitigation\n",
    "ax3.bar(\n",
    "    [\"A\", \"B\"],\n",
    "    pred_df[pred_df[\"y_test_mitigation\"] == 0][\"RAC\"].value_counts(),\n",
    "    color=\"#f77189\",\n",
    ")\n",
    "ax3.bar(\n",
    "    [\"A\", \"B\"],\n",
    "    pred_df[pred_df[\"y_test_mitigation\"] == 1][\"RAC\"].value_counts(),\n",
    "    color=\"#36ada4\",\n",
    ")\n",
    "\n",
    "ax3.legend([\"not awarded\", \"awarded\"])\n",
    "ax3.title.set_text('Predictions with bias mitigation')\n",
    "\n",
    "# Align y-axis\n",
    "ax2.sharey(ax1)\n",
    "ax3.sharey(ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is looking very promising indeed. We can clearly see that the model with bias mitigation has a much more balanced output across the groups A and B. There is one obvious issue with this - the model here assumes that our fictional government has grants to give to everyone who is deserving. In reality, this does not always hold true and we might need to look at another fairness metric that balances the outcomes while also restricting the total number of positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you for participating in the workshop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you finished this notebook quickly and want another challenge, try and implement another classification algorithm: Logistic Regression (don't get fooled by the name, this really is a classifier).\n",
    "\n",
    "The syntax for Logistic Regression is:\n",
    "\n",
    "```\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_lr = LogisticRegression(solver=\"liblinear\", penalty=\"l2\")\n",
    "```\n",
    "\n",
    "It is possible pass the bias_weights to the Logistic Regression algorithm in the [`.fit()` method](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.fit) by specifying `sample_weight = list(map(bias_weights.__getitem__, X_train.index))`. This will select the correct bias weights based on the index of the training data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the code here - this is purely optional in case you are done quickly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_lr = LogisticRegression(solver=\"liblinear\", penalty=\"l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight = list(map(bias_weights.__getitem__, X_train.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'LogisticRegression' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bp/n39rnln17tzd7f12lnw6br7w0000gr/T/ipykernel_14008/1949286373.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Complete the code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_predictions_mitigation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'LogisticRegression' object is not callable"
     ]
    }
   ],
   "source": [
    "# Complete the code here\n",
    "test_predictions_mitigation = KNN_Classifier(X_test, n_neighbors=5, weighted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
